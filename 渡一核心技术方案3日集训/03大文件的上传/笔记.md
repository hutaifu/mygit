## 大文件上传

背景
我们SaaS平台中包含企业资料，会议视频等大文件的上传，如果不作特殊处理，将遇到以下问题
1.网络中断，程序异常退出等问题导致文件上传失败，从而不得不全部重新上传
2.同一文件被不同用户反复上穿，白白占用网络和服务器资源

## 问题和方案
大文件上传普遍方案是文件分片。
分片的目标就把一个耗时的大事务划分为一个一个小事务。

由于公司具有BFF层来承接前端的文件请求，因此需要打通前后端所有跟文件上传的障碍。
基本上上了规模的公司，都会使用中间层服务器，只有用中间层服务器才会彻底实现前后
端分离。

分片上传主要障碍集中在：
1.如何减少页面阻塞
2.前后端如何协调
3.代码如何组织
4.前端代码中的复杂逻辑
5.BFF代码中的复杂逻辑

1.分片上传首要目标，尽量避免相同的分片重复上传，服务器必须要能够识别来自各个
客户端的各个上传请求中，是否存在与过去分片相同的上传请求。

如何识别相同文件，会耗费时间。
相同定义：文件内容一样即为相同。
可是对文件内容进行二进制的对比是一个非常耗时的操作，于是可以选择基于内容的
hash来进行对比。
hash是一种算法，可以将任何长度的数据转为定长的数据，常见的hash算法包括MD5,
SHA-1.  本节课使用MD5进行hash计算，使用第三方库Spark-MD5.
hash用来提升对比效率的工具。
文件内容1 ---》 hash1
文件内容2 ---》 hash2
(有非常小的几率会出现不是一一对应的关系，这里不考虑)，严格来说hash是二进制
数据，但是使用十六进制的字符串展现出来。

针对整个文件也是如此。
先计算分片文件hash,然后将分片后的hash再计算一次，得到整个文件的hash.
先对比整个文件的hash值，没有整个文件，再进行分片上传比较hash值。

可见客户端有两件事需要进行。
1.对文件进行分片，计算每个分片的hash值。
2.根据所有分片的hash值，计算真个文件的hash值。
分片代码
```js
 const blob = file.slice(0,1000);
```
计算hash是一件cpu密集型操作，如果不加处理将会长时间阻塞主线程。

解决计算出整个文件hash等待时间过长的问题：
假设用户上传的文件是新文件，在第一个分片结束后就进行判断hash值是否存在，然后上传操作，中途根据文件
的整体hash判断后续分片是否上传。
好处：对于新文件上传，缩短整体上传文件，旧文件只会发送少量的无效hash值的请求。

# 前后端如何协调
建立一个标准的通信协议。
核心交互：
1.创建文件2.hash校验3.分片数据上传4，分片合并

1.创建文件协议，用于获取文件上传的唯一标识。得到文件唯一id,文件分片大小等信息。

2.hash校验协议：分两种，校验，发送文件id,分片或者整体hash值，得到hash是否存在等信息，整体缺少的分片信息，整体文件的访问地址

3.分片数据上传协议，发送信息，文件id,分片编号，分片hash值，上传字节数，请求类型，
文件上传请求类型一般三种：application/octet-stream(二进制数据类型)，application/json(base64类型)，
multipart/form-data,传统格式，使用FormData构造器发送的数据。

4.分片合并协议，发送文件id,返回文件访问地址

代码如何组织
上传协议--> upload-core  --->  upload-client ,upload-serve;

upload-core包含;
1.发布订阅模式函数
注册事件，取消事件，
2.多任务并发执行，任务队列。Task任务构造器。

前端client:
对文件进行分片，分片方式多种：
1.普通分片，2.基于多线程的分片，3.基于主线程时间切片的分片，4.其他分片模式
考虑通用性，必须要向上层提供不同的分片模式，同时要允许上层自定义分片模式，因此
在设计上，使用基于抽象类的模板模式来完成处理。继承。抽象类，抽象方法->抽象其实就是
提重，抽象类中定义流程，流程中使用一个抽象方法，这个抽象方法不同的子类实现可能
会有所不同。

如何控制请求：
1.如何充分利用带宽。需要请求并发控制的机制
2.如何与上层请求库解锁，加一个中间层，定义接口，接口的实现我不管。要使用分片上传，
就必须实现这个接口。当然也能提供一个默认实现。这叫做策略模式。

后端代码中的复杂问题：
如何隔离不同的文件上层？
创建文件协议中，服务器使用uuid+jwt生成一个不被篡改的id

如何保证分片不重复：
1.不保存重复分片
2.不上传重复分片
不同文件可能有相同的部分分片，这部分相同分片也不能重复。
这就要求分片跨文件唯一，并且永不删除。
分片文件存储，记录文件和分片的对于关系。


合并分片到底做什么？：
1.极其耗时
2.数据冗余
所以服务器并不发生真正的合并，而是在数据库中记录文件中包含的分片。
因此，合并操作时，服务器仅做简单的处理：
1.校验文件的大小
2.校验文件的hash
3.标记文件的状态
4.生成文件访问地址

访问文件怎么办？:
使用taskQueue的并发控制，根据数据库中对于文件的分片记录，使用文件流依次读取分片数据，
用流管道直接响应给客户端即可。 


项目亮点：
从0到1开发真个uplad-sdk,该SDK为所有文件上传特别时大文件上传的场景提供前后端的支撑，
统一了所有文件的开发方式，完成了从底层协议，到工具类，到前端组件，再到后端中间间的开发。


在实现层面，为保证使用的灵活性，利用多种设计模式完成了SDK和上层应用的完全解耦，并对服务器
的存储结构进行了精细的设计，保证了存储和传输的唯一性。






























































